{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here a code for crawler web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can craw only 1 page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to icd10_data.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "url = \"https://naya.moph.go.th/table.php?p=databaseicd10\"\n",
    "\n",
    "# Initialize WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Run in headless mode (optional)\n",
    "service = Service(verbose = True)\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "try:\n",
    "    # Open the target URL\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for content to load (adjust if needed)\n",
    "\n",
    "    # Locate the table\n",
    "    table = driver.find_element(By.TAG_NAME, \"table\")\n",
    "    rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "    # Extract data\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        data.append([col.text for col in cols])\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    headers = [\"รหัสโรค\", \"ชื่อสามัญ\", \"ชื่อไทย\"]  # Adjust headers as necessary\n",
    "    df = pd.DataFrame(data[1:], columns=headers)  # Skip the header row in data\n",
    "\n",
    "    # Save to CSV\n",
    "    output_file = \"icd10_data.csv\"\n",
    "    df.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "\n",
    "finally:\n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to craw all page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "url = \"https://naya.moph.go.th/table.php?p=databaseicd10\"\n",
    "\n",
    "# Initialize WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Run in headless mode (optional)\n",
    "service = Service(verbose = True)\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "try:\n",
    "    # Open the target URL\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for content to load (adjust if needed)\n",
    "\n",
    "    # Initialize list to store all scraped data\n",
    "    all_data = []\n",
    "    \n",
    "    while True:\n",
    "        # Locate the table\n",
    "        table = driver.find_element(By.TAG_NAME, \"table\")\n",
    "        rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "        # Extract data from the table rows\n",
    "        data = []\n",
    "        for row in rows:\n",
    "            cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "            data.append([col.text for col in cols])\n",
    "\n",
    "        # Append the data of the current page (skip header)\n",
    "        all_data.extend(data[1:])  # Skipping the header row\n",
    "\n",
    "        # Check if \"Next\" button is present (for pagination)\n",
    "        try:\n",
    "            next_button = driver.find_element(By.XPATH, '//a[@aria-controls=\"dataTable\" and contains(text(), \"ถัดไป\")]')\n",
    "            next_button.click()\n",
    "            time.sleep(3)  # Wait for the next page to load (adjust if needed)\n",
    "        except:\n",
    "            # No more pages, break the loop\n",
    "            print(\"Reached the last page.\")\n",
    "            break\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    headers = [\"รหัสโรค\", \"ชื่อสามัญ\", \"ชื่อไทย\"]  # Adjust headers as necessary\n",
    "    df = pd.DataFrame(all_data, columns=headers)\n",
    "\n",
    "    # Save to CSV\n",
    "    output_file = \"icd10_data.csv\"\n",
    "    df.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "\n",
    "finally:\n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
